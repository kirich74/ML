{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate q-learning\n",
    "\n",
    "In this notebook you will teach a lasagne neural network to do Q-learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Frameworks__ - we'll accept this homework in any deep learning framework. For example, it translates to TensorFlow almost line-to-line. However, we recommend you to stick to theano/lasagne unless you're certain about your skills in the framework of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS='floatX=float32'\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS='floatX=float32'\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff3bd97e150>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAE4tJREFUeJzt3X+s3Xd93/Hna3FIKDCcgIOM7Syh\ndVuiajiJF4JoqzTQNkmjOpVKFTSNiEY1k4IEarU16aQ1aOsflVqyoU7R3IZiJpaQBmgsi42mJqjb\nHyQ4YIwdk8aUCN/aizPlB2RoWR3e++N8LpxcX9977o9z7z0fPx/S0fl+P+dzvufzuT5+nc/9nO/n\nflNVSJL6849WuwGSpPEw4CWpUwa8JHXKgJekThnwktQpA16SOjW2gE9yXZInkhxNcvu4XkeSNLuM\n4zz4JOcAfwv8IjAFfAV4b1U9vuwvJkma1bhG8FcBR6vq76rq/wH3ATvG9FqSpFmsG9NxNwHHhvan\ngLefqXISl9NqWb3+9Rv5sXM38P1/eIYXXjjxirKlmu2Yw2XScqmqLOX54wr42Rr1ihBPshPYOabX\n11nu537uA2x/8+Dttf/4LvbuvfMVZUsxfbwbb7zztNeQ1pJxTdFMAVuG9jcDx4crVNWuqtpeVdvH\n1AadpVYqePfuvZP9x3cBsP3NO7nxxvG8jrRY4wr4rwBbk1ya5FXAzcCeMb2WNKvp8O3ldaSFGkvA\nV9Up4IPAF4AjwP1VdXgcryUNGx69A2OfNhk+vqN4rTXjmoOnqj4PfH5cx5fmcqapmXGMtvfuvRNu\nZFnm96Xl5EpWdWPm6F06241tBC+tljON3sc5XfOKUfyN458akkZhwKsb0yG7mjxdUmvJWP5UwYIb\n4UInSTrNUhc6OQcvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMG\nvCR1yoCXpE4Z8JLUKQNekjq1pL8Hn+Qp4HvAy8Cpqtqe5ELg08AlwFPAb1TVc0trpiRpoZZjBP8L\nVbWtqra3/duBfVW1FdjX9iVJK2wcUzQ7gN1tezdw0xheQ5I0j6UGfAF/leSxJNNXO35TVZ0AaPcX\nLfE1JEmLsNRrsr6zqo4nuQh4KMk3R31i+0DYOW9FSdKiLNs1WZPcCbwI/BZwTVWdSLIR+FJV/dQ8\nz/WarJI0w6pdkzXJa5K8bnob+CXgELAHuKVVuwV4cCkNlCQtzqJH8EneAnyu7a4D/mtV/UGSNwD3\nAxcD3wHeU1XPznMsR/CSNMNSR/DLNkWzpEYY8JJ0mlWbopEkrW0GvCR1yoCXpE4Z8JLUKQNekjpl\nwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8\nJHXKgJekTs0b8Ek+nuRkkkNDZRcmeSjJk+3+glaeJB9LcjTJwSRXjLPxkqQzG2UE/wnguhlltwP7\nqmorsK/tA1wPbG23ncDdy9NMSdJCzRvwVfU3wLMzincAu9v2buCmofJP1sCXgfVJNi5XYyVJo1vs\nHPybquoEQLu/qJVvAo4N1ZtqZadJsjPJ/iT7F9kGSdIc1i3z8TJLWc1Wsap2AbsAksxaR5K0eIsd\nwT89PfXS7k+28ilgy1C9zcDxxTdPkrRYiw34PcAtbfsW4MGh8ve1s2muBl6YnsqRJK2sVM09O5Lk\nXuAa4I3A08DvA38J3A9cDHwHeE9VPZskwJ8wOOvm+8D7q2reOXanaCTpdFU127T3yOYN+JVgwEvS\n6ZYa8K5klaROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXA\nS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUqXkDPsnHk5xMcmio7M4kf5/kQLvdMPTYHUmO\nJnkiyS+Pq+GSpLmNctHtnwdeBD5ZVT/Tyu4EXqyqP5pR9zLgXuAq4M3AXwM/WVUvz/MaXpNVkmYY\n+zVZq+pvgGdHPN4O4L6qeqmqvg0cZRD2kqQVtpQ5+A8mOdimcC5oZZuAY0N1plrZaZLsTLI/yf4l\ntEGSdAaLDfi7gR8HtgEngD9u5bP9OjHr9EtV7aqq7VW1fZFtkCTNYVEBX1VPV9XLVfUD4E/50TTM\nFLBlqOpm4PjSmihJWoxFBXySjUO7vwZMn2GzB7g5yXlJLgW2Ao8urYmSpMVYN1+FJPcC1wBvTDIF\n/D5wTZJtDKZfngI+AFBVh5PcDzwOnAJum+8MGknSeMx7muSKNMLTJCXpNGM/TVKSNJkMeEnqlAEv\nSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLU\nKQNekjplwEtSpwx4SerUvAGfZEuSh5McSXI4yYda+YVJHkryZLu/oJUnyceSHE1yMMkV4+6EJOl0\no4zgTwG/U1VvBa4GbktyGXA7sK+qtgL72j7A9cDWdtsJ3L3srZYkzWvegK+qE1X11bb9PeAIsAnY\nAexu1XYDN7XtHcAna+DLwPokG5e95ZKkOS1oDj7JJcDlwCPAm6rqBAw+BICLWrVNwLGhp021spnH\n2plkf5L9C2+2JGk+60atmOS1wGeAD1fVd5OcseosZXVaQdUuYFc79mmPS5KWZqQRfJJzGYT7p6rq\ns6346empl3Z/spVPAVuGnr4ZOL48zZUkjWqUs2gC3AMcqaqPDj20B7ilbd8CPDhU/r52Ns3VwAvT\nUzmSpJWTqrlnR5L8LPA/gG8AP2jFv8dgHv5+4GLgO8B7qurZ9oHwJ8B1wPeB91fVnPPsTtFI0umq\n6oxz4aOYN+BXggEvSadbasC7klWSOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNe\nkjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqdGuej2liQPJzmS5HCS\nD7XyO5P8fZID7XbD0HPuSHI0yRNJfnmcHZAkzW6Ui25vBDZW1VeTvA54DLgJ+A3gxar6oxn1LwPu\nBa4C3gz8NfCTVfXyHK/hNVklaYaxX5O1qk5U1Vfb9veAI8CmOZ6yA7ivql6qqm8DRxmEvSRpBS1o\nDj7JJcDlwCOt6INJDib5eJILWtkm4NjQ06aY+wNBAqCq2L9/tVux+vwZaLmsG7ViktcCnwE+XFXf\nTXI38O+Aavd/DPwmMNuvFKdNwSTZCexcTKPVt9kCbvv2lW/HajpTyJ9tPwctzUgBn+RcBuH+qar6\nLEBVPT30+J8Ce9vuFLBl6OmbgeMzj1lVu4Bd7fkrOgc/wvcOK9QSjcrAG/DDTwsxylk0Ae4BjlTV\nR4fKNw5V+zXgUNveA9yc5LwklwJbgUeXr8kLV1WvuI1aX5Im2Sgj+HcC/wL4RpIDrez3gPcm2cZg\n+uUp4AMAVXU4yf3A48Ap4La5zqBZLuMI5NmO6eh+dThKHfDnoIWY9zTJFWnEiFM0a6GtszH0l0dV\n8dhjOetDbP9+g1wDSz1Ncs0F/Fpoz1IZ+ItTVf7spCFjPw9+JVx55ZVdzXvPnPPvpV+SJsvIp0lq\naZzPl7TS1sQI/mzl6F7SODmCXwMc3UsaBwN+jTrTyN7glzQqA37CONqXNCoDvgOGvqTZGPCdMvQl\nGfBnkeHQN+yl/hnwZylH+FL/DHj9kCN8qS8GvGZl2EuTz4DXvAx7aTIZ8FoQw16aHP4tGi2af0tH\nWtscwWvJHNVLa5MBr2Vl2EtrxygX3T4/yaNJvp7kcJKPtPJLkzyS5Mkkn07yqlZ+Xts/2h6/ZLxd\n0FrlBU+khZv+P3PllVcu+VijzMG/BFxbVW8DtgHXJbka+EPgrqraCjwH3Nrq3wo8V1U/AdzV6uks\nZ9hLsxvn1d/mDfgaeLHtnttuBVwLPNDKdwM3te0dbZ/2+Lvi7+oaYtjrbLdS/wdGOosmyTlJDgAn\ngYeAbwHPV9WpVmUK2NS2NwHHANrjLwBvWM5Gqx/Db3THAerZagxsRvqStapeBrYlWQ98DnjrbNXa\n/Wz/S0/rUZKdwE6Aiy++eKTGqm+O6F/JD7w+rOb7ekHnwVfV88CXgKuB9UmmPyA2A8fb9hSwBaA9\n/nrg2VmOtauqtlfV9g0bNiyu9VLHZs7NznbT2rRW/o1GOYtmQxu5k+TVwLuBI8DDwK+3arcAD7bt\nPW2f9vgXa7V7KXXKD4G1Yy3+zEeZotkI7E5yDoMPhPuram+Sx4H7kvx74GvAPa3+PcB/SXKUwcj9\n5jG0W9KIRgmccU0HLXfYraVpq7UU5Gcyb8BX1UHg8lnK/w64apby/wu8Z1laJ2lFTEJYwcLaOY4P\ng0n5OU1zJaukLi3Xh8GkhfowA17SWW+SQ3wu/jVJSeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkD\nXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnRrno9vlJHk3y9SSH\nk3yklX8iybeTHGi3ba08ST6W5GiSg0muGHcnJEmnG+WKTi8B11bVi0nOBf5nkv/WHvtXVfXAjPrX\nA1vb7e3A3e1ekrSC5h3B18CLbffcdpvr+lY7gE+2530ZWJ9k49KbKklaiJHm4JOck+QAcBJ4qKoe\naQ/9QZuGuSvJea1sE3Bs6OlTrUyStIJGCviqermqtgGbgauS/AxwB/DTwD8DLgR+t1Wf7fLkp434\nk+xMsj/J/meeeWZRjZckndmCzqKpqueBLwHXVdWJNg3zEvDnwFWt2hSwZehpm4HjsxxrV1Vtr6rt\nGzZsWFTjJUlnNspZNBuSrG/brwbeDXxzel49SYCbgEPtKXuA97Wzaa4GXqiqE2NpvSTpjEY5i2Yj\nsDvJOQw+EO6vqr1JvphkA4MpmQPAv2z1Pw/cABwFvg+8f/mbLUmaz7wBX1UHgctnKb/2DPULuG3p\nTZMkLYUrWSWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z\n8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROjRzwSc5J8rUke9v+pUkeSfJkkk8n\neVUrP6/tH22PXzKepkuS5rKQEfyHgCND+38I3FVVW4HngFtb+a3Ac1X1E8BdrZ4kaYWNFPBJNgO/\nAvxZ2w9wLfBAq7IbuKlt72j7tMff1epLklbQuhHr/QfgXwOva/tvAJ6vqlNtfwrY1LY3AccAqupU\nkhda/f89fMAkO4GdbfelJIcW1YO1743M6Hsneu0X9Ns3+zVZ/kmSnVW1a7EHmDfgk9wInKyqx5Jc\nM108S9Ua4bEfFQwavau9xv6q2j5SiydMr33rtV/Qb9/s1+RJsp+Wk4sxygj+ncCvJrkBOB/4xwxG\n9OuTrGuj+M3A8VZ/CtgCTCVZB7weeHaxDZQkLc68c/BVdUdVba6qS4CbgS9W1T8HHgZ+vVW7BXiw\nbe9p+7THv1hVp43gJUnjtZTz4H8X+O0kRxnMsd/Tyu8B3tDKfxu4fYRjLfpXkAnQa9967Rf02zf7\nNXmW1Lc4uJakPrmSVZI6teoBn+S6JE+0la+jTOesKUk+nuTk8GmeSS5M8lBb5ftQkgtaeZJ8rPX1\nYJIrVq/lc0uyJcnDSY4kOZzkQ618ovuW5Pwkjyb5euvXR1p5Fyuze11xnuSpJN9IcqCdWTLx70WA\nJOuTPJDkm+3/2juWs1+rGvBJzgH+E3A9cBnw3iSXrWabFuETwHUzym4H9rVVvvv40fcQ1wNb220n\ncPcKtXExTgG/U1VvBa4Gbmv/NpPet5eAa6vqbcA24LokV9PPyuyeV5z/QlVtGzolctLfiwD/Efjv\nVfXTwNsY/NstX7+qatVuwDuALwzt3wHcsZptWmQ/LgEODe0/AWxs2xuBJ9r2fwbeO1u9tX5jcJbU\nL/bUN+DHgK8Cb2ewUGZdK//h+xL4AvCOtr2u1ctqt/0M/dncAuFaYC+DNSkT36/WxqeAN84om+j3\nIoNTzr898+e+nP1a7SmaH656bYZXxE6yN1XVCYB2f1Ern8j+tl/fLwceoYO+tWmMA8BJ4CHgW4y4\nMhuYXpm9Fk2vOP9B2x95xTlru18wWCz5V0kea6vgYfLfi28BngH+vE2r/VmS17CM/VrtgB9p1WtH\nJq6/SV4LfAb4cFV9d66qs5Styb5V1ctVtY3BiPcq4K2zVWv3E9GvDK04Hy6epepE9WvIO6vqCgbT\nFLcl+fk56k5K39YBVwB3V9XlwP9h7tPKF9yv1Q746VWv04ZXxE6yp5NsBGj3J1v5RPU3ybkMwv1T\nVfXZVtxF3wCq6nngSwy+Y1jfVl7D7CuzWeMrs6dXnD8F3MdgmuaHK85bnUnsFwBVdbzdnwQ+x+CD\nedLfi1PAVFU90vYfYBD4y9av1Q74rwBb2zf9r2KwUnbPKrdpOQyv5p25yvd97dvwq4EXpn8VW2uS\nhMGitSNV9dGhhya6b0k2JFnftl8NvJvBF1sTvTK7Ol5xnuQ1SV43vQ38EnCICX8vVtX/Ao4l+alW\n9C7gcZazX2vgi4YbgL9lMA/6b1a7PYto/73ACeAfGHzC3spgLnMf8GS7v7DVDYOzhr4FfAPYvtrt\nn6NfP8vg17+DwIF2u2HS+wb8U+BrrV+HgH/byt8CPAocBf4COK+Vn9/2j7bH37LafRihj9cAe3vp\nV+vD19vt8HROTPp7sbV1G7C/vR//ErhgOfvlSlZJ6tRqT9FIksbEgJekThnwktQpA16SOmXAS1Kn\nDHhJ6pQBL0mdMuAlqVP/H+61A6/EDyQOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3c3e6d910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\").env\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate (deep) Q-learning: building the network\n",
    "\n",
    "In this section we will build and train naive Q-learning with theano/lasagne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is initializing input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "#create input variables. We'll support multiple states at once\n",
    "\n",
    "\n",
    "current_states = T.matrix(\"states[batch,units]\")\n",
    "actions = T.ivector(\"action_ids[batch]\")\n",
    "rewards = T.vector(\"rewards[batch]\")\n",
    "next_states = T.matrix(\"next states[batch,units]\")\n",
    "is_end = T.ivector(\"vector[batch] where 1 means that session just ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.nonlinearities import rectify\n",
    "#input layer\n",
    "l_states = InputLayer((None,)+state_dim)\n",
    "\n",
    "\n",
    "# <Your architecture. Please start with a single-layer network>\n",
    "\n",
    "\n",
    "nn = DenseLayer(l_states, 124, nonlinearity=rectify)\n",
    "nn = DenseLayer(nn, 64, nonlinearity=rectify)\n",
    "\n",
    "\n",
    "#output layer\n",
    "l_qvalues = DenseLayer(nn,num_units=n_actions,nonlinearity=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Q-values for `current_states`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get q-values for ALL actions in current_states\n",
    "predicted_qvalues = get_output(l_qvalues,{l_states:current_states})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compiling agent's \"GetQValues\" function\n",
    "get_qvalues = theano.function([current_states], T.argmax(predicted_qvalues, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select q-values for chosen actions\n",
    "predicted_qvalues_for_actions = predicted_qvalues[T.arange(actions.shape[0]),actions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function and `update`\n",
    "Here we write a function similar to `agent.update`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict q-values for next states\n",
    "predicted_next_qvalues = get_output(l_qvalues,{l_states:next_states})\n",
    "\n",
    "\n",
    "#Computing target q-values under \n",
    "gamma = 0.99\n",
    "target_qvalues_for_actions = rewards + gamma * T.max(predicted_next_qvalues, axis=1)\n",
    "\n",
    "#zero-out q-values at the end\n",
    "target_qvalues_for_actions = (1-is_end)*target_qvalues_for_actions\n",
    "\n",
    "#don't compute gradient over target q-values (consider constant)\n",
    "target_qvalues_for_actions = theano.gradient.disconnected_grad(target_qvalues_for_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#mean squared error loss function\n",
    "loss = lasagne.objectives.squared_error(predicted_qvalues_for_actions, target_qvalues_for_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all network weights\n",
    "all_weights = get_all_params(l_qvalues,trainable=True)\n",
    "\n",
    "#network updates. Note the small learning rate (for stability)\n",
    "updates = lasagne.updates.adam(loss.mean(),all_weights,learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training function that resembles agent.update(state,action,reward,next_state) \n",
    "#with 1 more argument meaning is_end\n",
    "train_step = theano.function([current_states, actions, rewards, next_states, is_end],\n",
    "                             updates=updates, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0.25 #initial epsilon\n",
    "\n",
    "def generate_session(t_max=1000):\n",
    "    \"\"\"play env with approximate q-learning agent and train it at the same time\"\"\"\n",
    "    \n",
    "    total_reward = 0\n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        \n",
    "        #get action q-values from the network\n",
    "        q_values = get_qvalues(np.array([s],dtype=np.float32))[0] \n",
    "        rnd = np.random.uniform()\n",
    "        if rnd < epsilon:\n",
    "            a = np.random.choice(np.arange(n_actions))\n",
    "        else:\n",
    "            a = q_values\n",
    "        \n",
    "        new_s,r,done,info = env.step(a)\n",
    "        \n",
    "        #train agent one step. Note that we use one-element arrays instead of scalars \n",
    "        #because that's what function accepts.\n",
    "        train_step(np.array([s],dtype=np.float32),[a],[r],\n",
    "                   np.array([new_s],dtype=np.float32),[done])\n",
    "        \n",
    "        total_reward+=r\n",
    "        \n",
    "        s = new_s\n",
    "        if done: break\n",
    "            \n",
    "    return total_reward\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\tmean reward:-132.394\tepsilon:0.24750\n",
      "epoch:1\tmean reward:-59.082\tepsilon:0.24502\n",
      "epoch:2\tmean reward:-45.605\tepsilon:0.24257\n",
      "epoch:3\tmean reward:18.706\tepsilon:0.24015\n",
      "You Win!\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    \n",
    "    rewards = [generate_session() for _ in range(100)] #generate new sessions\n",
    "    \n",
    "    epsilon*=0.99\n",
    "    print (\"epoch:%d\\tmean reward:%.3f\\tepsilon:%.5f\"%(i,np.mean(rewards),epsilon))\n",
    "\n",
    "    if np.mean(rewards) > 0:\n",
    "        print (\"You Win!\")\n",
    "        break\n",
    "        \n",
    "    assert epsilon!=0, \"Please explore environment\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
